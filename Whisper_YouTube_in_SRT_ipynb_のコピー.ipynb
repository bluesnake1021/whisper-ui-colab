{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluesnake1021/whisper-ui-colab/blob/main/Whisper_YouTube_in_SRT_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "H4rxNhsEpr-c"
      },
      "cell_type": "code",
      "source": [
        "#@title INSTALL DEPENDENCIES\n",
        "!pip install -q ffmpeg-python git+https://github.com/openai/whisper.git > /dev/null --q\n",
        "!pip install -q gradio\n",
        "!pip install -q pytube\n",
        "!pip install -q vtt_to_srt3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Launch the APP\n",
        "\n",
        "import gradio as gr\n",
        "from pytube import YouTube\n",
        "import os\n",
        "import subprocess\n",
        "import uuid\n",
        "from vtt_to_srt import vtt_to_srt\n",
        "\n",
        "def transcribe_youtube(source_language, model_size, youtube_link, source_file=None):\n",
        "  audio = str(uuid.uuid4()) + '.m4a'\n",
        "  if(os.path.exists(audio)):\n",
        "    os.remove(audio)\n",
        "    os.remove(audio + '.vtt')\n",
        "    os.remove(audio + '.srt')\n",
        "\n",
        "  if youtube_link != \"\":\n",
        "    yt = YouTube(youtube_link)\n",
        "    yt.streams.filter(only_audio=True)[0].download(filename=audio)\n",
        "    subprocess.run('whisper ' + audio + ' --language ' + str(source_language) + ' --model ' + str(model_size), shell=True)\n",
        "  \n",
        "  # A logic to process an uploaded audio file\n",
        "  elif source_file is not None:\n",
        "    subprocess.run('whisper ' + source_file + ' --language ' + str(source_language) + ' --model ' + str(model_size), shell=True)\n",
        "    audio = source_file.split(\"/\")[2]\n",
        "  else:\n",
        "      return \"You must either provide a YouTube link or a source file\"\n",
        "  \n",
        "  path = '/content/' + audio + '.vtt'\n",
        "  vtt_to_srt(path)\n",
        "  with open('/content/' + audio + '.srt','r') as file:\n",
        "    data=file.read()\n",
        "  return data,'/content/' + audio + '.srt'\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=transcribe_youtube,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=1, placeholder=\"enter the source language (Japanese, English, etc)\"),\n",
        "        gr.Dropdown(label=\"Model Size\", choices=['base','small', 'medium', 'large'], value='large'),\n",
        "        gr.Textbox(lines=2, placeholder=\"paste youtube link here\"),\n",
        "        # A gradio inteface to upload an audio file\n",
        "        gr.Audio(source=\"upload\", type=\"filepath\")\n",
        "    ],\n",
        "    outputs=[gr.Textbox(label=\"Transcripts\"),gr.File(label=\"Download Transcripts\")],\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "wAkVkxq6octM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcribe an audio file that is uploaded to the content folder."
      ],
      "metadata": {
        "id": "S4SymL7e5ai_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the \"audio.m4a\" file name so that it matches with the file name\n",
        "# you uploaded to the content folder\n",
        "\n",
        "!whisper audio.m4a --language Japanese --model large"
      ],
      "metadata": {
        "id": "S6XR74jhFGcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translate transcripts into English"
      ],
      "metadata": {
        "id": "q8MJTSN55qDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Again change the \"audio.m4a\" file name so that it matches with the file name\n",
        "# you uploaded to the content folder\n",
        "\n",
        "!whisper audio.m4a --language Japanese --model large --task translate"
      ],
      "metadata": {
        "id": "KCu1wXCj5uUa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}